{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Revision Question 1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "meJhM9SjDkbv",
        "u59ZLRUwAYy0",
        "0IXQpGS7DCBh",
        "Z2XRPesbDYcn",
        "x6pGdekpD-Oh",
        "Irk3V3dSGIGe"
      ],
      "authorship_tag": "ABX9TyPXBxvc7VmtvWqWhn07JxzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengy90/RHUL-CS5200-Tutorials/blob/master/Tutorial%20Sheets/Revision_Question_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meJhM9SjDkbv",
        "colab_type": "text"
      },
      "source": [
        "###### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxJH1JGcDikk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u59ZLRUwAYy0",
        "colab_type": "text"
      },
      "source": [
        "### **1.Give the definision of depth one Markov Chain**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7zWpjlODURb",
        "colab_type": "text"
      },
      "source": [
        "$P(H_{T=t}|H_{T=1},H_{T=2},...,H_{T=t-1}) = P(H_{T=t}|H_{T=t-1})$\n",
        "\n",
        "Current value of H only depends on the previous 1 value of H.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IXQpGS7DCBh",
        "colab_type": "text"
      },
      "source": [
        "### **2. This question is based on Wikipedia article “Markov chain”**\n",
        "\n",
        "A week on a stock exchange can be characterised as bull market (with prices going up), bear market (with prices going down), or stagnant (with prices staying at about the same level). Let us describe the market by a Markov chain with the following transition probabilities:\n",
        "\n",
        "![Fig 1](https://github.com/shengy90/RHUL-CS5200-Tutorials/blob/master/Tutorial%20Sheets/msc/rev1fig1.png?raw=true)![alt text](https://)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2XRPesbDYcn",
        "colab_type": "text"
      },
      "source": [
        "##### **a. Write down the transition matrix M for the chain (assume the order: bull, bear, stagment)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp0lF240Dfiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = np.array([[0.9, 0.075, 0.025],\n",
        "              [0.15, 0.8, 0.05],\n",
        "              [0.5, 0.25, 0.25]\n",
        "              ])\n",
        "print(f\"Transition matrix M: \\n{M}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6pGdekpD-Oh",
        "colab_type": "text"
      },
      "source": [
        "##### **b. Assuming the initial probabilities of bear market as 0.4, bull market as 0.4 and stagnant market as 0.2, calculate the probability to get the sequence of weeks bull, bull, stagnant, bear, bull.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xo-0FA7EJl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P_BullBullStagBearBull = 0.4 * 0.9 * 0.025 * 0.25 * 0.15\n",
        "print(f\"P(Bull, Bull, Stagnant, Bear, Bull): \\n {P_BullBullStagBearBull}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnPWowyJEswm",
        "colab_type": "text"
      },
      "source": [
        "##### **c. Work out the 2- and 3-step transition chain.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kdZROEEl_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M2 = np.linalg.matrix_power(M, 2)\n",
        "M3 = np.linalg.matrix_power(M, 3)\n",
        "print(f\"M2:\\n{M2}\\n M3:\\n{M3}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vk_XU_oFSyU",
        "colab_type": "text"
      },
      "source": [
        "##### **d. Assuming the initial probabilities as above, calculate the probability of the 3rd week being bull market.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBnPrSJWFMpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P = [0.4, 0.4, 0.2]\n",
        "PM2 = np.dot(P, M2)\n",
        "print(f\"Probably of third week being bull market: \\n{PM2[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DgzwcwpFrin",
        "colab_type": "text"
      },
      "source": [
        "##### **e. Calculate the stationary distribution of the Markov chain.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBvRiC8PFoNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M_inf = np.linalg.matrix_power(M, 99999)\n",
        "PM_inf = np.dot(P, M_inf)\n",
        "print(f\"Stationary distribution of the Markov chain: \\n{PM_inf}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irk3V3dSGIGe",
        "colab_type": "text"
      },
      "source": [
        "### **3. The following sequence of weeks has been observed: bull, bull, bear, bull, stagnant, bear, bull, bull, bear, stagnant, stagnant, bull, bull, bear.** \n",
        "\n",
        "##### Assuming that this sequence was generated by a first-order Markov chain, find the maximum likelihood estimate of the transition probabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRYZZv_SGkTP",
        "colab_type": "text"
      },
      "source": [
        "Transition counts:\n",
        "\n",
        "${bull,bull}$ = 3 \n",
        "\n",
        "${bull,bear}$ = 3 \n",
        "\n",
        "${bull,stagnant}$ = 1 \n",
        "\n",
        "${bear,bull}$ = 2 \n",
        "\n",
        "${bear,bear}$ = 0 \n",
        "\n",
        "${bear,stagnant}$ = 1 \n",
        "\n",
        "${stagnant,bull}$ = 1 \n",
        "\n",
        "${stagnant,bear}$ = 1 \n",
        "\n",
        "${stagnant,stagnant}$ = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mmfvp1eG1nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bull = np.array([3,3,1])\n",
        "bear = np.array([2,0,1])\n",
        "stag = np.array([1,1,1])\n",
        "\n",
        "M = np.array([\n",
        "              [bull[0]/np.sum(bull), bull[1]/np.sum(bull), bull[2]/np.sum(bull)],\n",
        "              [bear[0]/np.sum(bear), bear[1]/np.sum(bear), bear[2]/np.sum(bear)],\n",
        "              [stag[0]/np.sum(stag), stag[1]/np.sum(stag), stag[2]/np.sum(stag)]\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym5B3Bl6IyjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Maximum likelihood estimate of the transition probabilities:\\n{M}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjOUcRnI7rk",
        "colab_type": "text"
      },
      "source": [
        "### **4. Consider a set of three pages. Page 1 links 2 and 3; page 2 links 3; page 3 links 1. Calculate their page rank using the damping factor d = 0.85.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6k3_fYEJBIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 3\n",
        "d = 0.85\n",
        "M = np.zeros([N,N])\n",
        "pagelinks = np.ones([N,N])\n",
        "\n",
        "page1links = np.array([0,1,1])\n",
        "page2links = np.array([0,0,1])\n",
        "page3links = np.array([1,0,0])\n",
        "pagelinks[0] = page1links\n",
        "pagelinks[1] = page2links\n",
        "pagelinks[2] = page3links\n",
        "\n",
        "for i in range(N):\n",
        "    for j in range(N):\n",
        "        numerator = pagelinks[i,j]\n",
        "        denominator = np.sum(pagelinks[i])\n",
        "        M[i, j] = (1-d)/N + d*numerator/denominator\n",
        "\n",
        "print(f\"Transition Matrix: \\n{M}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoC869tKKn0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M_inf = np.linalg.matrix_power(M, 99999)\n",
        "print(M_inf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uFGAZAeNPoU",
        "colab_type": "text"
      },
      "source": [
        "Given enough time, the user will always end up in the stationary distribution regardless of where they started from. The page ranks are 0.388, 0.215 and 0.397 respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fONTqyKNfaY",
        "colab_type": "text"
      },
      "source": [
        "### **5. What is the role of the damping factor? Explain its meaning in the browsing model and its theoretical significance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8d9WQYNsSy",
        "colab_type": "text"
      },
      "source": [
        "The damping factor represents the probability that a user would quit browsing the pages. By introducing this damping factor, we ensure that the transition matrix will always converge towards $M_{\\infty}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvzCcB_AOLky",
        "colab_type": "text"
      },
      "source": [
        "### **6. Why have link-based ranking methods become less popular recently?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-o5bsS1OQ9U",
        "colab_type": "text"
      },
      "source": [
        "They have become too easily manipulated by search engine marketeers, and therefore defeats the purpose of the algorithim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkUqP08hOX7c",
        "colab_type": "text"
      },
      "source": [
        "### **7. Describe the method of sampling from a univariate distribution based on the inverted distribution function $F^{-1}$. What are its drawbacks?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf9eLFN-Otmu",
        "colab_type": "text"
      },
      "source": [
        "This method might be difficult for some distributions (although we might be able to apply some adhoc hacks). It also doesn't generalise well to higher dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9e2Ucc-O_Tq",
        "colab_type": "text"
      },
      "source": [
        "### **8. Formulate the detailed balance condition for a distribution p and a Markov chain with the transition matrix M. Prove that the condition is sufficient for p to be the stationary distribution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th3z8d4rPiPo",
        "colab_type": "text"
      },
      "source": [
        "Proof that if the detailed balance condition: $P_{i}P_{i,j}$ = $P_{j}P_{j,i}$ is met, then P will be the stationary distribution of M:\n",
        "\n",
        "Let us calculate PM; the j-th element is:\n",
        "\n",
        "$\\sum_{i=1}^{n} P_{i}P_{i,j} = \\sum_{i=1}^{n} P_{j}P_{j,i} = P_{j} \\sum_{i=1}^{n}p_{j,i} = P_{i}$\n",
        "\n",
        "because each row sums to 1!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF0gLoUYRvU6",
        "colab_type": "text"
      },
      "source": [
        "### **9. Is it possible for a Markov chain to have a stationary distribution and not to converge to it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PXuyJo8Rzap",
        "colab_type": "text"
      },
      "source": [
        "Yes. If not all the elements in the matrix are strictly positive (either 0 or very small), then there's a change that the matrix might not converge. The exact condition for matrix to converge is the Perron-Frobenius theorem. An example : the identity matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD1e_dD4SNvA",
        "colab_type": "text"
      },
      "source": [
        "### **10. Describe the Metropolis-Hastings algorithm.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4_csgbWSR0b",
        "colab_type": "text"
      },
      "source": [
        "1. Start from an arbitrary region (call it $h_{1}$).\n",
        "\n",
        "2. Sample $h_{t}$ from a proposal distribution, $q(x|h_{t})$. \n",
        "\n",
        "3. Calculate the acceptance probability, a = $min \\left( 1, \\frac{p(x)q(h_{t}|x)}{p(h_{t})q(x|h_{t})} \\right)$.\n",
        "\n",
        "4. Draw a random 's' uniformly distributed on [0, 1]. If $s \\leq a$, we let $h_{t+1} = x$. Else, $h_{t+1} = h_{t}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_qmnU2xWeNG",
        "colab_type": "text"
      },
      "source": [
        "### **11. Suppose that the Metropolis-Hastings algorithm is used to sample from a univariate distribution with $p(x) \\space \\alpha \\space e^{-x^4} $.**\n",
        "\n",
        "The gaussian proposal distribution is used:\n",
        "$$q(v|u) = \\frac{1}{\\sqrt{2\\pi}} e^{(v-u)^2/2}$$\n",
        "\n",
        "Let $h_{t}$ = 0.5. Suppose that x=1 has been sampled from the proposal distribution. Calculate the acceptance probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u1TqJD7YsZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gauss(v, u):\n",
        "    q_v_u = 1/np.sqrt(2*np.pi) * np.exp((v-u)**2/2)\n",
        "    return q_v_u\n",
        "\n",
        "def px(x):\n",
        "    return np.exp(-x**4)\n",
        "\n",
        "def acceptance_probability(numerator, denominator):\n",
        "    return min(1, numerator/ denominator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1eSCZh5YuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_t = 0.5\n",
        "x = 1 \n",
        "\n",
        "numerator = px(x)*gauss(h_t, x)\n",
        "denominator = px(h_t)*gauss(x, h_t)\n",
        "print(f\"Acceptance probability = {acceptance_probability(numerator, denominator)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccri93xQZ6QF",
        "colab_type": "text"
      },
      "source": [
        "### **12. Answer the previous question if the proposal distribution has variance $\\sigma^2$ rather than 1.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ajNHv7xaVCg",
        "colab_type": "text"
      },
      "source": [
        "It wouldn't make a difference. The variance term would be cancelled out when we divide the numerator by the denominator when calculating the acceptance probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw9Dlv6ta_Wy",
        "colab_type": "text"
      },
      "source": [
        "### **13. Can we get independent samples with MCMC?**\n",
        "\n",
        "No. By definition, $h_{t+1}$ is not independent of $h_{t}$. However, if we do require independent samples, we could choose to skip some $h_{t}$s (calculate, but not output them) to get 'independent' samples. "
      ]
    }
  ]
}